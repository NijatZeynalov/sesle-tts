{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e286f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import commons, utils\n",
    "from models import SynthesizerTrn\n",
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "import re\n",
    "import sounddevice as sd\n",
    "import tempfile\n",
    "import torch\n",
    "from num2azerbaijani import convert as num2aze \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "209e798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMapper(object):\n",
    "    def __init__(self, vocab_file):\n",
    "        self.symbols = [\n",
    "            x.replace(\"\\n\", \"\") for x in open(vocab_file, encoding=\"utf-8\").readlines()\n",
    "        ]\n",
    "        self.SPACE_ID = self.symbols.index(\" \")\n",
    "        self._symbol_to_id = {s: i for i, s in enumerate(self.symbols)}\n",
    "        self._id_to_symbol = {i: s for i, s in enumerate(self.symbols)}\n",
    "\n",
    "    def text_to_sequence(self, text, cleaner_names):\n",
    "        \"\"\"Converts a string of text to a sequence of IDs corresponding to the symbols in the text.\n",
    "        Args:\n",
    "        text: string to convert to a sequence\n",
    "        cleaner_names: names of the cleaner functions to run the text through\n",
    "        Returns:\n",
    "        List of integers corresponding to the symbols in the text\n",
    "        \"\"\"\n",
    "        sequence = []\n",
    "        clean_text = text.strip()\n",
    "        for symbol in clean_text:\n",
    "            symbol_id = self._symbol_to_id[symbol]\n",
    "            sequence += [symbol_id]\n",
    "        return sequence\n",
    "\n",
    "    def uromanize(self, text, uroman_pl):\n",
    "        iso = \"xxx\"\n",
    "        with tempfile.NamedTemporaryFile() as tf, tempfile.NamedTemporaryFile() as tf2:\n",
    "            with open(tf.name, \"w\") as f:\n",
    "                f.write(\"\\n\".join([text]))\n",
    "            cmd = f\"perl \" + uroman_pl\n",
    "            cmd += f\" -l {iso} \"\n",
    "            cmd += f\" < {tf.name} > {tf2.name}\"\n",
    "            os.system(cmd)\n",
    "            outtexts = []\n",
    "            with open(tf2.name) as f:\n",
    "                for line in f:\n",
    "                    line = re.sub(r\"\\s+\", \" \", line).strip()\n",
    "                    outtexts.append(line)\n",
    "            outtext = outtexts[0]\n",
    "        return outtext\n",
    "\n",
    "    def get_text(self, text, hps):\n",
    "        text_norm = self.text_to_sequence(text, hps.data.text_cleaners)\n",
    "        if hps.data.add_blank:\n",
    "            text_norm = commons.intersperse(text_norm, 0)\n",
    "        text_norm = torch.LongTensor(text_norm)\n",
    "        return text_norm\n",
    "\n",
    "    def filter_oov(self, text, lang=None):\n",
    "        text = self.preprocess_char(text, lang=lang)\n",
    "        val_chars = self._symbol_to_id\n",
    "        txt_filt = \"\".join(list(filter(lambda x: x in val_chars, text)))\n",
    "        return txt_filt\n",
    "\n",
    "    def preprocess_char(self, text, lang=None):\n",
    "        \"\"\"\n",
    "        Special treatement of characters in certain languages\n",
    "        \"\"\"\n",
    "        if lang == \"ron\":\n",
    "            text = text.replace(\"ț\", \"ţ\")\n",
    "            print(f\"{lang} (ț -> ţ): {text}\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e7fcb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(text, lang, speed):\n",
    "\n",
    "    if speed is None:\n",
    "        speed = 1.0\n",
    "\n",
    "    lang_code = lang.split(\":\")[0].strip()\n",
    "\n",
    "    vocab_file = hf_hub_download(\n",
    "        repo_id=\"facebook/mms-tts\",\n",
    "        filename=\"vocab.txt\",\n",
    "        subfolder=f\"models/{lang_code}\",\n",
    "    )\n",
    "    config_file = hf_hub_download(\n",
    "        repo_id=\"facebook/mms-tts\",\n",
    "        filename=\"config.json\",\n",
    "        subfolder=f\"models/{lang_code}\",\n",
    "    )\n",
    "    g_pth = hf_hub_download(\n",
    "        repo_id=\"facebook/mms-tts\",\n",
    "        filename=\"G_100000.pth\",\n",
    "        subfolder=f\"models/{lang_code}\",\n",
    "    )\n",
    "\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    print(f\"Run inference with {device}\")\n",
    "\n",
    "    assert os.path.isfile(config_file), f\"{config_file} doesn't exist\"\n",
    "    hps = utils.get_hparams_from_file(config_file)\n",
    "    text_mapper = TextMapper(vocab_file)\n",
    "    net_g = SynthesizerTrn(\n",
    "        len(text_mapper.symbols),\n",
    "        hps.data.filter_length // 2 + 1,\n",
    "        hps.train.segment_size // hps.data.hop_length,\n",
    "        **hps.model,\n",
    "    )\n",
    "    net_g.to(device)\n",
    "    _ = net_g.eval()\n",
    "\n",
    "    _ = utils.load_checkpoint(g_pth, net_g, None)\n",
    "\n",
    "    is_uroman = hps.data.training_files.split(\".\")[-1] == \"uroman\"\n",
    "\n",
    "    if is_uroman:\n",
    "        uroman_dir = \"uroman\"\n",
    "        assert os.path.exists(uroman_dir)\n",
    "        uroman_pl = os.path.join(uroman_dir, \"bin\", \"uroman.pl\")\n",
    "        text = text_mapper.uromanize(text, uroman_pl)\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text_mapper.filter_oov(text, lang=lang)\n",
    "    stn_tst = text_mapper.get_text(text, hps)\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.unsqueeze(0).to(device)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)\n",
    "        hyp = (\n",
    "            net_g.infer(\n",
    "                x_tst,\n",
    "                x_tst_lengths,\n",
    "                noise_scale=0.5,\n",
    "                noise_scale_w=0.5,\n",
    "                length_scale=1.0 / speed,\n",
    "            )[0][0, 0]\n",
    "            .cpu()\n",
    "            .float()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "    return (hps.data.sampling_rate, hyp), text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "315c5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "string = 'Güney Azərbaycanın 4 şəhəri susuz qalıb.Lent.az bu barədə \"MOUZE\" teleqram kanalına istinadla bildirir. Məlumata görə, Su və Kanalizasiya Şirkətinin baş direktoru Məhəmməd Xani qeyd edib ki, 550 kənd susuzluqdan əziyyət çəkir:“Təbriz, Mərənd, Səhənd və Şəhr Baxşaiş şəhərlərində kritik vəziyyətlə üzləşirik, lakin biz bu vəziyyətdən çıxmağa çalışırıq və bu layihələrə ayrılan vəsait yalnız vəziyyətə nəzarət etmək üçündür”.'\n",
    "\n",
    "numbers = re.findall(r'\\d+', string)\n",
    "\n",
    "numbers = [int(num) for num in numbers]\n",
    "result = {}\n",
    "\n",
    "for number in numbers:\n",
    "    result[number] = num2aze(number)\n",
    "    \n",
    "for num, word in result.items():\n",
    "    string = string.replace(str(num), word)\n",
    "\n",
    "string = string.replace('.', '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b33d196b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/mms-tts/resolve/main/models/azj-script_latin/vocab.txt HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/mms-tts/resolve/main/models/azj-script_latin/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /facebook/mms-tts/resolve/main/models/azj-script_latin/G_100000.pth HTTP/1.1\" 302 0\n",
      "Run inference with cpu\n",
      "INFO:root:Loaded checkpoint '/Users/nijatz/.cache/huggingface/hub/models--facebook--mms-tts/snapshots/0bc63ca058a89750bccd3a82b706b33f7478eb42/models/azj-script_latin/G_100000.pth' (iteration 8334)\n",
      "güney azərbaycanın dörd  şəhəri susuz qalıb lent az bu barədə mouze teleqram kanalına istinadla bildirir  məlumata görə su və kanalizasiya şirkətinin baş direktoru məhəmməd xani qeyd edib ki beş yüz əlli  kənd susuzluqdan əziyyət çəkirtəbriz mərənd səhənd və şəhr baxşaiş şəhərlərində kritik vəziyyətlə üzləşirik lakin biz bu vəziyyətdən çıxmağa çalışırıq və bu layihələrə ayrılan vəsait yalnız vəziyyətə nəzarət etmək üçündür \n"
     ]
    }
   ],
   "source": [
    "gra = synthesize(string,'azj-script_latin',1.2)\n",
    "print(gra[1])\n",
    "sd.play(gra[0][1], gra[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2335d4c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on doqquz '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ae791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
